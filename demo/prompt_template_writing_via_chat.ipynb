{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template Writing with AI Editors via interactive chats\n",
    "\n",
    "In this demo, we interact with the LLM prompt editor to write a prompt template. We use the prompt template for diagnosis and diagnosis attributes (date, status) frame extraction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r'/home/daviden1013/David_projects/llm-ie/test'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, r\"/home/daviden1013/David_projects/llm-ie/src\")\n",
    "\n",
    "from llm_ie.engines import OllamaInferenceEngine\n",
    "from llm_ie.extractors import SentenceFrameExtractor\n",
    "from llm_ie.prompt_editor import PromptEditor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with defining a LLM inference engine and LLM. In this demo, we use Ollama to run Llama 3.1 70B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a LLM inference engine\n",
    "llm = OllamaInferenceEngine(model_name=\"llama3.1:70b-instruct-q8_0\", max_ctx=16000, keep_alive=3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define LLM-based editor and start a chat session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c092dae05f34641b66e9703790bafe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Type your message here...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0e38d389a2473ca2f821032a511480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hello! Welcome to our conversation about prompt development. I'm here to help you refine, rewrite, and generate effective prompts based on the guidelines provided.\n",
      "\n",
      "Before we begin, could you please share what kind of task or project you're working on? Are you looking to create a new prompt from scratch or improve an existing one? Additionally, do you have any specific requirements or constraints that I should be aware of?\n",
      "\n",
      "Feel free to provide as much context as possible, and I'll do my best to assist you in crafting a well-structured and effective prompt.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Write a prompt to pull diagnosis with date and status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Here is a prompt to extract diagnoses with dates and statuses:\n",
      "\n",
      "**Task Description**\n",
      "This task involves extracting medical diagnoses from clinical text, along with their corresponding dates and statuses.\n",
      "\n",
      "**Schema Definition**\n",
      "\n",
      "* **Diagnosis**: the name of the medical condition or disease\n",
      "* **Date**: the date when the diagnosis was made or updated (in YYYY-MM-DD format)\n",
      "* **Status**: the current status of the diagnosis (e.g. \"Active\", \"Resolved\", \"Chronic\")\n",
      "\n",
      "**Output Format Definition**\n",
      "The output should be a JSON list, where each element is a dictionary representing a diagnosis with its corresponding date and status.\n",
      "\n",
      "Example:\n",
      "```\n",
      "[\n",
      "  {\"Diagnosis\": \"Hypertension\", \"Date\": \"2020-01-15\", \"Status\": \"Active\"},\n",
      "  {\"Diagnosis\": \"Type 2 Diabetes\", \"Date\": \"2018-06-20\", \"Status\": \"Chronic\"},\n",
      "  {\"Diagnosis\": \"Pneumonia\", \"Date\": \"2022-02-10\", \"Status\": \"Resolved\"}\n",
      "]\n",
      "```\n",
      "\n",
      "**Input Placeholder**\n",
      "Please provide the clinical text from which to extract the diagnoses with dates and statuses.\n",
      "\n",
      "{{input}}\n",
      "\n",
      "Let me know if you'd like me to modify or expand on this prompt!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "editor = PromptEditor(llm, SentenceFrameExtractor)\n",
    "editor.chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
